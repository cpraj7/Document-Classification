{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prajwal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk import stem\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn import model_selection\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.layers import Embedding\n",
    "\n",
    "from keras.layers import SpatialDropout1D\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set path and load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\Prajwal_DS_Course\\CUTe\\7321c_CUTe\\train.csv\n"
     ]
    }
   ],
   "source": [
    "# set working directory\n",
    "os.chdir(\"F://Prajwal_DS_Course//CUTe//7321c_CUTe/\")\n",
    "\n",
    "# Define path\n",
    "PATH = os.getcwd()\n",
    "\n",
    "# Define File name\n",
    "FILE_NAME = \"train.csv\"\n",
    "\n",
    "# Define full path with file name\n",
    "FILE = os.path.join(PATH + \"\\\\\" + FILE_NAME)\n",
    "\n",
    "# Print \n",
    "print(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat = []\n",
    "converse = []\n",
    "\n",
    "with open(FILE) as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=\",\")\n",
    "    headers = next(readCSV) # Ignore Header\n",
    "    for row in readCSV:\n",
    "        category = row[1]\n",
    "        convers = row[2]\n",
    "        cat.append(category)\n",
    "        converse.append(convers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASK_A_DOCTOR</td>\n",
       "      <td>mom wants to know if the drugname needs some d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASK_A_DOCTOR</td>\n",
       "      <td>patients to discuss drugname she says she has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MISCELLANEOUS</td>\n",
       "      <td>letter of patient establishment request name s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>APPOINTMENTS</td>\n",
       "      <td>appointment question name mom appointments pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MISCELLANEOUS</td>\n",
       "      <td>please refax neurocog order to new wake medici...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0   ASK_A_DOCTOR  mom wants to know if the drugname needs some d...\n",
       "1   ASK_A_DOCTOR  patients to discuss drugname she says she has ...\n",
       "2  MISCELLANEOUS  letter of patient establishment request name s...\n",
       "3   APPOINTMENTS  appointment question name mom appointments pat...\n",
       "4  MISCELLANEOUS  please refax neurocog order to new wake medici..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "dict_new = {\n",
    "    'category': cat ,\n",
    "    'text': converse\n",
    "}\n",
    "\n",
    "dataset = pd.DataFrame(dict_new)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [category, text]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "dataset[dataset.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45825, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>converse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASK_A_DOCTOR</td>\n",
       "      <td>mom want know drugname need dosage adjusting n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASK_A_DOCTOR</td>\n",
       "      <td>patient discus drugname say weird ta patient p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MISCELLANEOUS</td>\n",
       "      <td>letter patient establishment request name spou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>APPOINTMENTS</td>\n",
       "      <td>appointment question name mom appointment pati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MISCELLANEOUS</td>\n",
       "      <td>please refax neurocog order new wake medicine ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                           converse\n",
       "0   ASK_A_DOCTOR  mom want know drugname need dosage adjusting n...\n",
       "1   ASK_A_DOCTOR  patient discus drugname say weird ta patient p...\n",
       "2  MISCELLANEOUS  letter patient establishment request name spou...\n",
       "3   APPOINTMENTS  appointment question name mom appointment pati...\n",
       "4  MISCELLANEOUS  please refax neurocog order new wake medicine ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stop words & lemmatize words\n",
    "w_tokenizer = WhitespaceTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "dataset[\"converse\"] = dataset['text'].apply(lambda x: \" \".join([lemmatizer.lemmatize(word) for word in x.split() if word not in (stop)]))\n",
    "\n",
    "dataset = dataset.drop([\"text\"], axis=1)\n",
    "\n",
    "print(dataset.shape)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading keras library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32695 unique tokens\n"
     ]
    }
   ],
   "source": [
    "# Prepare tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(dataset[\"converse\"])\n",
    "    \n",
    "word_Index = tokenizer.word_index\n",
    "\n",
    "vocab_Size = len(word_Index) + 1\n",
    "print(\"Found %s unique tokens\" % vocab_Size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (45825, 150)\n",
      "Shape of label tensor: (45825,)\n"
     ]
    }
   ],
   "source": [
    "# integer encode the documents\n",
    "sequences = tokenizer.texts_to_sequences(dataset[\"converse\"])\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 150\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "label = pd.factorize(dataset['category'])[0]\n",
    "\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRESCRIPTION     12077\n",
       "APPOINTMENTS     11098\n",
       "MISCELLANEOUS     9736\n",
       "ASK_A_DOCTOR      9440\n",
       "LAB               3457\n",
       "JUNK                17\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_Test, Y_train, Y_test = model_selection.train_test_split(data, \n",
    "                                                                    label, \n",
    "                                                                    random_state = 7, \n",
    "                                                                    stratify = label, \n",
    "                                                                    test_size = 0.15)\n",
    "\n",
    "y_train = to_categorical(Y_train)\n",
    "y_test = to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open(os.path.join(PATH, 'glove.6B.50d.txt'), encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "    \n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32695, 50)\n"
     ]
    }
   ],
   "source": [
    "embedding_Matrix = np.zeros((vocab_Size, 50))\n",
    "for word, i in word_Index.items():\n",
    "    embedding_Vector = embeddings_index.get(word)\n",
    "    if embedding_Vector is not None:\n",
    "        embedding_Matrix[i] = embedding_Vector\n",
    "\n",
    "print (embedding_Matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(vocab_Size,\n",
    "                            50,\n",
    "                            weights=[embedding_Matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 150, 50)           1634750   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 7500)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                480064    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 2,115,204\n",
      "Trainable params: 480,454\n",
      "Non-trainable params: 1,634,750\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "38951/38951 [==============================] - 20s 513us/step - loss: 0.9179 - acc: 0.6526\n",
      "Epoch 2/3\n",
      "38951/38951 [==============================] - 20s 515us/step - loss: 0.6854 - acc: 0.7412\n",
      "Epoch 3/3\n",
      "38951/38951 [==============================] - 19s 500us/step - loss: 0.5435 - acc: 0.7969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c8b1cbf080>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(len(np.unique(label)), activation='softmax' ))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred_t = model.predict(X_train)\n",
    "y_pred_t = []\n",
    "for i in Y_pred_t:\n",
    "    y_pred_t.append(np.argmax(i))\n",
    "\n",
    "Y_pred = model.predict(X_Test)\n",
    "y_pred =[]\n",
    "for i in Y_pred:\n",
    "    y_pred.append(np.argmax(i))\n",
    "\n",
    "# summarize the model\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Model Accuracy -  0.8743549587943826\n",
      "Test Model Accuracy -  0.6851905731742799\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "print(\"Train Model Accuracy - \" , metrics.accuracy_score(Y_train, y_pred_t))\n",
    "print(\"Test Model Accuracy - \" , metrics.accuracy_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build CNN Model with Pre-Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 150, 50)           1634750   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 146, 64)           16064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 36, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 32, 64)            20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 8, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 1,704,580\n",
      "Trainable params: 69,830\n",
      "Non-trainable params: 1,634,750\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "38951/38951 [==============================] - 1039s 27ms/step - loss: 0.7918 - acc: 0.7074\n",
      "Epoch 2/3\n",
      "38951/38951 [==============================] - 1073s 28ms/step - loss: 0.5935 - acc: 0.7823\n",
      "Epoch 3/3\n",
      "38951/38951 [==============================] - 1109s 28ms/step - loss: 0.5300 - acc: 0.8038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c8b87a6320>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model = Sequential()\n",
    "cnn_model.add(embedding_layer)\n",
    "cnn_model.add(Conv1D(64, 5, activation='relu'))\n",
    "cnn_model.add(MaxPooling1D(4))\n",
    "cnn_model.add(Conv1D(64, 5, activation='relu'))\n",
    "cnn_model.add(MaxPooling1D(4))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(64, activation='relu'))\n",
    "cnn_model.add(Dense(len(np.unique(label)), activation='softmax' ))\n",
    "cnn_model.summary()\n",
    "\n",
    "cnn_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(X_train, y_train, epochs=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_t = cnn_model.predict(X_train)\n",
    "y_pred_t = []\n",
    "for i in Y_pred_t:\n",
    "    y_pred_t.append(np.argmax(i))\n",
    "\n",
    "Y_pred = cnn_model.predict(X_Test)\n",
    "y_pred =[]\n",
    "for i in Y_pred:\n",
    "    y_pred.append(np.argmax(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Model Accuracy -  0.8318400041077251\n",
      "Test Model Accuracy -  0.7836776258364853\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "print(\"Train Model Accuracy - \" , metrics.accuracy_score(Y_train, y_pred_t))\n",
    "print(\"Test Model Accuracy - \" , metrics.accuracy_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 150, 50)           1634750   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 150, 50)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 1,702,004\n",
      "Trainable params: 67,254\n",
      "Non-trainable params: 1,634,750\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "38951/38951 [==============================] - 100s 3ms/step - loss: 1.0142 - acc: 0.6154\n",
      "Epoch 2/3\n",
      "38951/38951 [==============================] - 99s 3ms/step - loss: 0.7616 - acc: 0.7211\n",
      "Epoch 3/3\n",
      "38951/38951 [==============================] - 98s 3ms/step - loss: 0.6772 - acc: 0.7507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c8bb823630>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(embedding_layer)\n",
    "lstm_model.add(SpatialDropout1D(0.3))\n",
    "lstm_model.add(LSTM(100))\n",
    "lstm_model.add(Dense(64, activation = \"relu\"))\n",
    "lstm_model.add(Dropout(0.25))\n",
    "lstm_model.add(Dense(len(np.unique(label)), activation=\"softmax\"))\n",
    "lstm_model.summary()\n",
    "\n",
    "lstm_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "lstm_model.fit(X_train, y_train, epochs=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_t = lstm_model.predict(X_train)\n",
    "y_pred_t = []\n",
    "for i in Y_pred_t:\n",
    "    y_pred_t.append(np.argmax(i))\n",
    "\n",
    "Y_pred = lstm_model.predict(X_Test)\n",
    "y_pred =[]\n",
    "for i in Y_pred:\n",
    "    y_pred.append(np.argmax(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Model Accuracy -  0.7845498190033632\n",
      "Test Model Accuracy -  0.7832411987198138\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "print(\"Train Model Accuracy - \" , metrics.accuracy_score(Y_train, y_pred_t))\n",
    "print(\"Test Model Accuracy - \" , metrics.accuracy_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
